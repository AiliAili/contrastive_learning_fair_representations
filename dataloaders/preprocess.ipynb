{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('null_space': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5eca252ff42feaa38633fdf3f1b2dad6af180befe6921a10ff95c099934938e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_dataset(path):\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        \n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def load_dictionary(path):\n",
    "    \n",
    "    with open(path, \"r\", encoding = \"utf-8\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        \n",
    "    k2v, v2k = {}, {}\n",
    "    for line in lines:\n",
    "        \n",
    "        k,v = line.strip().split(\"\\t\")\n",
    "        v = int(v)\n",
    "        k2v[k] = v\n",
    "        v2k[v] = k\n",
    "    \n",
    "    return k2v, v2k\n",
    "    \n",
    "def count_profs_and_gender(data):\n",
    "    \n",
    "    counter = defaultdict(Counter)\n",
    "    for entry in data:\n",
    "        gender, prof = entry[\"g\"], entry[\"p\"]\n",
    "        counter[prof][gender] += 1\n",
    "        \n",
    "    return counter\n",
    "\n",
    "def count_profs_and_race(data):\n",
    "    \n",
    "    counter = defaultdict(Counter)\n",
    "    for entry in data:\n",
    "        gender, prof = entry[\"economy\"], entry[\"p\"]\n",
    "        counter[prof][gender] += 1\n",
    "        \n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_word_vectors(fname):\n",
    "    \n",
    "    model = KeyedVectors.load_word2vec_format(fname, binary=False)\n",
    "    vecs = model.vectors\n",
    "    words = list(model.vocab.keys())\n",
    "    return model, vecs, words\n",
    "\n",
    "\n",
    "def get_embeddings_based_dataset(data, word2vec_model, p2i, filter_stopwords = False):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    unk, total = 0., 0.\n",
    "    unknown = []\n",
    "    vocab_counter = Counter()\n",
    "    \n",
    "    for entry in tqdm.tqdm_notebook(data, total = len(data)):\n",
    "        y = p2i[entry[\"p\"]]\n",
    "        words = entry[\"hard_text\"].split(\" \")\n",
    "        if filter_stopwords:\n",
    "            words = [w for w in words if w.lower() not in STOPWORDS]\n",
    "            \n",
    "        vocab_counter.update(words) \n",
    "        bagofwords = np.sum([word2vec_model[w] if w in word2vec_model else word2vec_model[\"unk\"] for w in words], axis = 0)\n",
    "        #print(bagofwords.shape)\n",
    "        X.append(bagofwords)\n",
    "        Y.append(y)\n",
    "        total += len(words)\n",
    "        \n",
    "        unknown_entry = [w for w in words if w not in word2vec_model]\n",
    "        unknown.extend(unknown_entry)\n",
    "        unk += len(unknown_entry)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    print(\"% unknown: {}\".format(unk/total))\n",
    "    return X,Y,unknown,vocab_counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/xudongh1/Project/joint_debiasing/data/bios/biasbios_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path / \"train_with_location_current_red.pkl\", \"rb\") as f:\n",
    "    train_loc_sub = pickle.load(f)\n",
    "\n",
    "with open(data_path / \"dev_with_location_current_red.pkl\", \"rb\") as f:\n",
    "    dev_loc_sub = pickle.load(f)\n",
    "\n",
    "with open(data_path / \"test_with_location_current_red.pkl\", \"rb\") as f:\n",
    "    test_loc_sub = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlp_project_path = Path(\"/home/xudongh1/Project/nullspace_projection\")\n",
    "\n",
    "p2i, i2p = load_dictionary( inlp_project_path / \"data/biasbios/profession2index.txt\")\n",
    "g2i, i2g = load_dictionary( inlp_project_path / \"data/biasbios/gender2index.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['g', 'p', 'text', 'start', 'hard_text', 'hard_text_untokenized', 'text_without_gender', 'location', 'country', 'economy', 'econ_class'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_loc_sub[1].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'m': 40115, 'f': 34753})"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "Counter([i['g'] for i in train_loc_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'attorney': 5994,\n",
       "         'photographer': 7440,\n",
       "         'painter': 1695,\n",
       "         'psychologist': 4310,\n",
       "         'filmmaker': 1885,\n",
       "         'architect': 1678,\n",
       "         'rapper': 470,\n",
       "         'physician': 4713,\n",
       "         'professor': 13411,\n",
       "         'dentist': 5423,\n",
       "         'accountant': 585,\n",
       "         'model': 2381,\n",
       "         'nurse': 6853,\n",
       "         'surgeon': 4226,\n",
       "         'chiropractor': 880,\n",
       "         'paralegal': 181,\n",
       "         'journalist': 4038,\n",
       "         'pastor': 610,\n",
       "         'personal_trainer': 181,\n",
       "         'comedian': 603,\n",
       "         'dj': 393,\n",
       "         'poet': 1589,\n",
       "         'software_engineer': 640,\n",
       "         'teacher': 2474,\n",
       "         'dietitian': 681,\n",
       "         'composer': 1024,\n",
       "         'interior_designer': 285,\n",
       "         'yoga_teacher': 225})"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "Counter([i['p'] for i in train_loc_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({1: 62704, 0: 12164})"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "Counter([i['econ_class'] for i in train_loc_sub])"
   ]
  },
  {
   "source": [
    "# Create DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df = pd.DataFrame(train_loc_sub)\n",
    "bios_dev_df = pd.DataFrame(dev_loc_sub)\n",
    "bios_test_df = pd.DataFrame(test_loc_sub)"
   ]
  },
  {
   "source": [
    "# Get BERT encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f15f62e5f7e543abbbdbbf138f24f767"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd2f4a95a7d14dcea3294cf2501768e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8985b5ad886f45e2823b95320b7cb4b0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (BertModel, BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, df):\n",
    "    \"\"\"\n",
    "    Iterate over the data and tokenize it. Sequences longer than 512 tokens are trimmed.\n",
    "    :param tokenizer: tokenizer to use for tokenization\n",
    "    :param data: data to tokenize\n",
    "    :return: a list of the entire tokenized data\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "    for row in tqdm(df['hard_text']):\n",
    "        tokens = tokenizer.encode(row, add_special_tokens=True)\n",
    "        # keeping a maximum length of bert tokens: 512\n",
    "        tokenized_data.append(tokens[:512])\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 56%|█████▋    | 42298/74868 [00:58<00:43, 753.40it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 74868/74868 [01:42<00:00, 727.35it/s]\n",
      "100%|██████████| 11902/11902 [00:14<00:00, 805.84it/s]\n",
      "100%|██████████| 26202/26202 [00:38<00:00, 675.23it/s]\n"
     ]
    }
   ],
   "source": [
    "bios_train_tokens = tokenize(tokenizer, bios_train_df)\n",
    "bios_dev_tokens = tokenize(tokenizer, bios_dev_df)\n",
    "bios_test_tokens = tokenize(tokenizer, bios_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df[\"BERT_tokens\"] = bios_train_tokens\n",
    "bios_dev_df[\"BERT_tokens\"] = bios_dev_tokens\n",
    "bios_test_df[\"BERT_tokens\"] = bios_test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios_train_df.to_pickle(\"bios_train_df\")\n",
    "# bios_dev_df.to_pickle(\"bios_dev_df\")\n",
    "# bios_test_df.to_pickle(\"bios_test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(model, data):\n",
    "    \"\"\"\n",
    "    encode the text\n",
    "    :param model: encoding model\n",
    "    :param data: data\n",
    "    :return: two numpy matrices of the data:\n",
    "                first: average of all tokens in each sentence\n",
    "                second: cls token of each sentence\n",
    "    \"\"\"\n",
    "    all_data_cls = []\n",
    "    all_data_avg = []\n",
    "    batch = []\n",
    "    for row in tqdm(data):\n",
    "        batch.append(row)\n",
    "        input_ids = torch.tensor(batch).cuda()\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_ids)[0].detach().cpu()\n",
    "            all_data_avg.append(last_hidden_states.squeeze(0).mean(dim=0).numpy())\n",
    "            all_data_cls.append(last_hidden_states.squeeze(0)[0].numpy())\n",
    "        batch = []\n",
    "    return np.array(all_data_avg), np.array(all_data_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 74868/74868 [17:54<00:00, 69.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_avg_data, train_cls_data = encode_text(model, bios_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df[\"train_avg_data\"] = list(train_avg_data)\n",
    "bios_train_df[\"train_cls_data\"] = list(train_cls_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios_train_df.to_pickle(\"bios_train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11902/11902 [02:52<00:00, 68.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_avg_data, dev_cls_data = encode_text(model, bios_dev_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_dev_df[\"train_avg_data\"] = list(dev_avg_data)\n",
    "bios_dev_df[\"train_cls_data\"] = list(dev_cls_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios_dev_df.to_pickle(\"bios_dev_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26202/26202 [06:28<00:00, 67.38it/s]\n"
     ]
    }
   ],
   "source": [
    "test_avg_data, test_cls_data = encode_text(model, bios_test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_test_df[\"train_avg_data\"] = list(test_avg_data)\n",
    "bios_test_df[\"train_cls_data\"] = list(test_cls_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios_test_df.to_pickle(\"bios_test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_main_label = [p2i[p] for p in bios_train_df[\"p\"]]\n",
    "bios_dev_main_label = [p2i[p] for p in bios_dev_df[\"p\"]]\n",
    "bios_test_main_label = [p2i[p] for p in bios_test_df[\"p\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_gender_label = [g2i[g] for g in bios_train_df[\"g\"]]\n",
    "bios_dev_gender_label = [g2i[g] for g in bios_dev_df[\"g\"]]\n",
    "bios_test_gender_label = [g2i[g] for g in bios_test_df[\"g\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df[\"gender_class\"] = bios_train_gender_label\n",
    "bios_dev_df[\"gender_class\"] = bios_dev_gender_label\n",
    "bios_test_df[\"gender_class\"] = bios_test_gender_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df[\"profession_class\"] = bios_train_main_label\n",
    "bios_dev_df[\"profession_class\"] = bios_dev_main_label\n",
    "bios_test_df[\"profession_class\"] = bios_test_main_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_train_df.to_pickle(\"bios_train_df.pkl\")\n",
    "bios_dev_df.to_pickle(\"bios_dev_df.pkl\")\n",
    "bios_test_df.to_pickle(\"bios_test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "01, 2058, 1996, 5109, 1010, 2002, 2038, 5845...   \n",
       "\n",
       "                                          train_avg_data  \\\n",
       "0      [-0.21925582, 0.3185657, -0.082215905, -0.2758...   \n",
       "1      [-0.3420705, 0.08448499, -0.14151192, -0.07653...   \n",
       "2      [-0.44729003, 0.11454038, 0.05102728, -0.06796...   \n",
       "3      [0.33411, 0.121224634, -0.053565085, -0.329597...   \n",
       "4      [-0.08476864, 0.15655439, 0.011266252, -0.3253...   \n",
       "...                                                  ...   \n",
       "26197  [-0.27369493, 0.024090193, 0.105042726, -0.109...   \n",
       "26198  [-0.08720053, -0.06562692, -0.008284882, -0.18...   \n",
       "26199  [0.0804553, 0.026444903, 0.13191348, -0.030254...   \n",
       "26200  [0.14391442, 0.14700025, -0.093546554, -0.2743...   \n",
       "26201  [-0.013628161, 0.08085996, 0.067136765, -0.261...   \n",
       "\n",
       "                                          train_cls_data  gender_class  \\\n",
       "0      [-0.3803718, -0.097306155, -0.8822688, -0.6219...             1   \n",
       "1      [-0.39880997, -0.000994616, -0.7533077, -0.208...             0   \n",
       "2      [-0.21576567, -0.2939665, -0.72540194, -0.2641...             0   \n",
       "3      [-0.40261286, 0.17509018, -0.30223414, -0.6536...             0   \n",
       "4      [-0.17510362, 0.039392967, -0.7716085, -0.7649...             1   \n",
       "...                                                  ...           ...   \n",
       "26197  [-0.1305432, 0.023827186, -0.52613086, -0.4801...             1   \n",
       "26198  [-0.11247709, -0.022806767, -0.78408843, -0.79...             1   \n",
       "26199  [-0.17706892, -0.03509802, -0.1651837, -0.4455...             0   \n",
       "26200  [-0.18534903, -0.08657265, -0.2575438, -0.7811...             1   \n",
       "26201  [-0.037867647, -0.12744595, -0.2819793, -0.402...             0   \n",
       "\n",
       "       profession_class  \n",
       "0                    26  \n",
       "1                    21  \n",
       "2                    21  \n",
       "3                     6  \n",
       "4                    16  \n",
       "...                 ...  \n",
       "26197                21  \n",
       "26198                11  \n",
       "26199                18  \n",
       "26200                25  \n",
       "26201                25  \n",
       "\n",
       "[26202 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>g</th>\n      <th>p</th>\n      <th>text</th>\n      <th>start</th>\n      <th>hard_text</th>\n      <th>hard_text_untokenized</th>\n      <th>text_without_gender</th>\n      <th>location</th>\n      <th>country</th>\n      <th>economy</th>\n      <th>econ_class</th>\n      <th>BERT_tokens</th>\n      <th>train_avg_data</th>\n      <th>train_cls_data</th>\n      <th>gender_class</th>\n      <th>profession_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f</td>\n      <td>teacher</td>\n      <td>Samantha Gamble is a music teacher at Swift El...</td>\n      <td>83</td>\n      <td>Gamble works to integrate the arts into core s...</td>\n      <td>Gamble works to integrate the arts into core s...</td>\n      <td>_ works to integrate the arts into core subjec...</td>\n      <td>[Chicago, Illinois]</td>\n      <td>united states</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 18503, 2573, 2000, 17409, 1996, 2840, 20...</td>\n      <td>[-0.21925582, 0.3185657, -0.082215905, -0.2758...</td>\n      <td>[-0.3803718, -0.097306155, -0.8822688, -0.6219...</td>\n      <td>1</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>m</td>\n      <td>professor</td>\n      <td>Miguel Esteban is an Assistant Professor in th...</td>\n      <td>126</td>\n      <td>There , his research and teaching relates to t...</td>\n      <td>There, his research and teaching relates to th...</td>\n      <td>There, _ research and teaching relates to the ...</td>\n      <td>[Japan]</td>\n      <td>japan</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2045, 1010, 2010, 2470, 1998, 4252, 1462...</td>\n      <td>[-0.3420705, 0.08448499, -0.14151192, -0.07653...</td>\n      <td>[-0.39880997, -0.000994616, -0.7533077, -0.208...</td>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>m</td>\n      <td>professor</td>\n      <td>Dr. Neil Rubens is an Assistant Professor at t...</td>\n      <td>123</td>\n      <td>He is the Director of Active Intelligence Rese...</td>\n      <td>He is the Director of Active Intelligence Rese...</td>\n      <td>_ is the Director of Active Intelligence Resea...</td>\n      <td>[Japan]</td>\n      <td>japan</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2002, 2003, 1996, 2472, 1997, 3161, 4454...</td>\n      <td>[-0.44729003, 0.11454038, 0.05102728, -0.06796...</td>\n      <td>[-0.21576567, -0.2939665, -0.72540194, -0.2641...</td>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>m</td>\n      <td>dentist</td>\n      <td>Dr. Bhagirath Rajpurohit is a Dentist in Kudi,...</td>\n      <td>102</td>\n      <td>Dr. Bhagirath Rajpurohit practices at Satyam D...</td>\n      <td>Dr. Bhagirath Rajpurohit practices at Satyam D...</td>\n      <td>Dr. _ _ practices at Satyam Dental Clinic in K...</td>\n      <td>[Kudi, Jodhpur]</td>\n      <td>india</td>\n      <td>Lower middle income (LM)</td>\n      <td>0</td>\n      <td>[101, 2852, 1012, 1038, 3270, 5856, 27362, 119...</td>\n      <td>[0.33411, 0.121224634, -0.053565085, -0.329597...</td>\n      <td>[-0.40261286, 0.17509018, -0.30223414, -0.6536...</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f</td>\n      <td>pastor</td>\n      <td>Carol Howard Merritt is a pastor at Western Pr...</td>\n      <td>83</td>\n      <td>Western is a traditional , intergenerational c...</td>\n      <td>Western is a traditional, intergenerational co...</td>\n      <td>Western is a traditional, intergenerational co...</td>\n      <td>[Washington]</td>\n      <td>united states</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2530, 2003, 1037, 3151, 1010, 6970, 6914...</td>\n      <td>[-0.08476864, 0.15655439, 0.011266252, -0.3253...</td>\n      <td>[-0.17510362, 0.039392967, -0.7716085, -0.7649...</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26197</th>\n      <td>f</td>\n      <td>professor</td>\n      <td>Masami Toku is an associate professor of art e...</td>\n      <td>93</td>\n      <td>She is the general director of the project Pow...</td>\n      <td>She is the general director of the project Pow...</td>\n      <td>_ is the general director of the project Power...</td>\n      <td>[Chico]</td>\n      <td>united states</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2016, 2003, 1996, 2236, 2472, 1997, 1996...</td>\n      <td>[-0.27369493, 0.024090193, 0.105042726, -0.109...</td>\n      <td>[-0.1305432, 0.023827186, -0.52613086, -0.4801...</td>\n      <td>1</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>26198</th>\n      <td>f</td>\n      <td>journalist</td>\n      <td>Journalist Gabrielle Paluch is a freelance jou...</td>\n      <td>108</td>\n      <td>She worked as an editor at the Myanmar Times ,...</td>\n      <td>She worked as an editor at the Myanmar Times, ...</td>\n      <td>_ worked as an editor at the Myanmar Times, wh...</td>\n      <td>[Myanmar, Thailand]</td>\n      <td>thailand</td>\n      <td>Upper middle income (UM)</td>\n      <td>0</td>\n      <td>[101, 2016, 2499, 2004, 2019, 3559, 2012, 1996...</td>\n      <td>[-0.08720053, -0.06562692, -0.008284882, -0.18...</td>\n      <td>[-0.11247709, -0.022806767, -0.78408843, -0.79...</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>26199</th>\n      <td>m</td>\n      <td>photographer</td>\n      <td>Photographer Alexander Lupascu is a photograph...</td>\n      <td>161</td>\n      <td>He started shooting back in 2006 and got into ...</td>\n      <td>He started shooting back in 2006 and got into ...</td>\n      <td>_ started shooting back in 2006 and got into w...</td>\n      <td>[Romania]</td>\n      <td>romania</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2002, 2318, 5008, 2067, 1999, 2294, 1998...</td>\n      <td>[0.0804553, 0.026444903, 0.13191348, -0.030254...</td>\n      <td>[-0.17706892, -0.03509802, -0.1651837, -0.4455...</td>\n      <td>0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>26200</th>\n      <td>f</td>\n      <td>surgeon</td>\n      <td>Dr. G Santhi Vardhani is a General Surgeon in ...</td>\n      <td>115</td>\n      <td>Dr. G Santhi Vardhani practices at Tulasi Hosp...</td>\n      <td>Dr. G Santhi Vardhani practices at Tulasi Hosp...</td>\n      <td>Dr. G _ _ practices at Tulasi Hospitals in Kus...</td>\n      <td>[Hyderabad, Kushaiguda]</td>\n      <td>india</td>\n      <td>Lower middle income (LM)</td>\n      <td>0</td>\n      <td>[101, 2852, 1012, 1043, 15548, 4048, 13075, 17...</td>\n      <td>[0.14391442, 0.14700025, -0.093546554, -0.2743...</td>\n      <td>[-0.18534903, -0.08657265, -0.2575438, -0.7811...</td>\n      <td>1</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>26201</th>\n      <td>m</td>\n      <td>surgeon</td>\n      <td>Dr. John Silverton is a leading plastic surgeo...</td>\n      <td>129</td>\n      <td>Over the decades , he has treated numerous ind...</td>\n      <td>Over the decades, he has treated numerous indi...</td>\n      <td>Over the decades, _ has treated numerous indiv...</td>\n      <td>[Modesto]</td>\n      <td>united states</td>\n      <td>High income (H)</td>\n      <td>1</td>\n      <td>[101, 2058, 1996, 5109, 1010, 2002, 2038, 5845...</td>\n      <td>[-0.013628161, 0.08085996, 0.067136765, -0.261...</td>\n      <td>[-0.037867647, -0.12744595, -0.2819793, -0.402...</td>\n      <td>0</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>26202 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "bios_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}